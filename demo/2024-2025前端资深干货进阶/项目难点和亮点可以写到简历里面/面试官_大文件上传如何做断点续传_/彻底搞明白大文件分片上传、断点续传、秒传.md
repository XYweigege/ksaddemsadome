### 代码
[big-file-uploader.zip](https://www.yuque.com/attachments/yuque/0/2024/zip/207857/1728697663581-930ae8aa-e727-4fab-9cb6-41e340794abe.zip)

### <font style="color:rgb(38, 38, 38);"> 原理</font>
+ <font style="color:rgb(38, 38, 38);">分片上传原理：客户端将选择的文件进行切分，每一个分片都单独发送请求到服务端；</font>
+ <font style="color:rgb(38, 38, 38);">断点续传 & 秒传原理：客户端发送请求询问服务端某文件的上传状态，服务端响应该文件已上传分片，客户端再将未上传分片上传即可；</font>
    - <font style="color:rgb(38, 38, 38);">如果没有需要上传的分片就是秒传；</font>
    - <font style="color:rgb(38, 38, 38);">如果有需要上传的分片就是断点续传；</font>
+ <font style="color:rgb(38, 38, 38);">每个文件要有自己唯一的标识，这个标识就是将整个文件进行MD5加密，这是一个Hash算法，将加密后的Hash值作为文件的唯一标识；</font>
    - <font style="color:rgb(38, 38, 38);">使用</font>`<font style="color:rgb(38, 38, 38);">spark-md5</font>`<font style="color:rgb(38, 38, 38);">第三方工具库</font>



#### 上传过程
![](https://cdn.nlark.com/yuque/0/2024/png/207857/1728635127535-92621e9a-b9e4-4110-ac35-8deea26f908b.png)

<br/>color1
+ <font style="color:rgb(38, 38, 38);">第一步：将文件进行分片，并计算其Hash值（文件的唯一标识）</font>
+ <font style="color:rgb(38, 38, 38);">第二步：发送请求，询问服务端文件的上传状态</font>
+ <font style="color:rgb(38, 38, 38);">第三步：根据文件上传状态进行后续上传</font>
    - <font style="color:rgb(38, 38, 38);">文件已经上传过了</font>
        * <font style="color:rgb(38, 38, 38);">结束 — 秒传功能</font>
    - <font style="color:rgb(38, 38, 38);">文件存在，但分片不完整</font>
        * <font style="color:rgb(38, 38, 38);">将未上传的分片进行上传 — 断点续传功能</font>
    - <font style="color:rgb(38, 38, 38);">文件不存在</font>
        * <font style="color:rgb(38, 38, 38);">将所有分片上传</font>
+ <font style="color:rgb(38, 38, 38);">第四步：文件分片全部上传后，发送请求通知服务端合并文件分片</font>

<br/>



### <font style="color:rgb(38, 38, 38);">前端详细流程</font>
<font style="color:rgb(38, 38, 38);">接下来就是最关键的实现部分了</font>

#### <font style="color:rgb(38, 38, 38);">分片上传入口</font>
<font style="color:rgb(38, 38, 38);">当我们选择一个要上传的文件后，点击上传触发上传回调函数，上传的回调函数需要如下参数：</font>

```javascript
/**
 * @param {File} targetFile 目标上传文件
 * @param {number} baseChunkSize 上传分块大小，单位Mb
 * @param {string} uploadUrl 上传文件的后端接口地址
 * @param {string} vertifyUrl 验证文件上传的接口地址
 * @param {string} mergeUrl 请求进行文件合并的接口地址
 * @param {Function} progress_cb 更新上传进度的回调函数
 * @returns {Promise}
 */
```

<font style="color:rgb(38, 38, 38);">接下来先给出大致代码思路然后逐一完善：</font>

```javascript
async function uploadFile(file, baseChunkSize, uploadUrl, vertifyUrl, mergeUrl, progress_cb) {
  1. 将文件进行分片并计算Hash值
  得到 allChunkList---所有分片   fileHash---文件的hash值
  2. 通过fileHash请求服务端，判断文件上传状态
  得到 neededFileList---待上传文件分片
  3. 同步上传进度，针对不同文件上传状态调用 progress_cb
  4. 发送上传请求
  5. 发送文件合并请求
}
```

#### <font style="color:rgb(38, 38, 38);">文件分片 & Hash计算</font>
```javascript
/**
 * 将目标文件分片 并 计算文件Hash
 * @param {File} targetFile 目标上传文件
 * @param {number} baseChunkSize 上传分块大小，单位Mb
 * @returns {chunkList:ArrayBuffer,fileHash:string}
 */
async function sliceFile(targetFile, baseChunkSize = 1) {
  return new Promise((resolve, reject) => {
    //初始化分片方法，兼容问题
    let blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice;
    //分片大小 baseChunkSize Mb
    let chunkSize = baseChunkSize * 1024 * 1024;
    //分片数
    let targetChunkCount = targetFile && Math.ceil(targetFile.size / chunkSize);
    //当前已执行分片数
    let currentChunkCount = 0;
    //当前以收集的分片
    let chunkList = [];
    //创建sparkMD5对象
    let spark = new SparkMD5.ArrayBuffer();
    //创建文件读取对象
    let fileReader = new FileReader();
    let fileHash = null;

    //FilerReader onload事件
    fileReader.onload = (e) => {
      //当前读取的分块结果 ArrayBuffer
      const curChunk = e.target.result;
      //将当前分块追加到spark对象中
      spark.append(curChunk);
      currentChunkCount++;
      chunkList.push(curChunk);
      //判断分块是否全部读取成功
      if (currentChunkCount >= targetChunkCount) {
        //全部读取，获取文件hash
        fileHash = spark.end();
        resolve({ chunkList, fileHash });
      } else {
        loadNext();
      }
    };

    //FilerReader onerror事件
    fileReader.onerror = () => {
      reject(null);
    };

    //读取下一个分块
    const loadNext = () => {
      //计算分片的起始位置和终止位置
      const start = chunkSize * currentChunkCount;
      let end = start + chunkSize;
      if (end > targetFile.size) {
        end = targetFile.size;
      }
      //读取文件，触发onLoad
      fileReader.readAsArrayBuffer(blobSlice.call(targetFile, start, end));
    };

    loadNext();
  });
}
```

#### <font style="color:rgb(38, 38, 38);">分片上传入口完善</font>
```javascript
async function uploadFile(file, baseChunkSize, uploadUrl, vertifyUrl, mergeUrl, progress_cb) {
  const { chunkList, fileHash } = await sliceFile(file, baseChunkSize);
  //所有分片 ArrayBuffer[]
  let allChunkList = chunkList;
  //需要上传的分片序列 number[]
  let neededChunkList = [];
  //上传进度
  let progress = 0;
  //发送请求,获取文件上传状态
  if (vertifyUrl) {
    const { data } = await requestInstance.post(vertifyUrl, {
      fileHash,
      totalCount: allChunkList.length,
      extname: '.' + file.name.split('.').pop(),
    });
    const { neededFileList, message } = data;
    if (message) console.info(message);
    //无待上传文件，秒传
    if (!neededFileList.length) {
      progress_cb(100);
      return;
    }

    //部分上传成功，更新unUploadChunkList
    neededChunkList = neededFileList;
  }

  //同步上传进度，断点续传情况下
  progress = ((allChunkList.length - neededChunkList.length) / allChunkList.length) * 100;

  //上传
  if (allChunkList.length) {
    const requestList = allChunkList.map(async (chunk, index) => {
      if (neededChunkList.includes(index + 1)) {
        const response = await uploadChunk(chunk, index + 1, fileHash, uploadUrl);
        //更新进度
        progress += Math.ceil(100 / allChunkList.length);
        if (progress >= 100) progress = 100;
        progress_cb(progress);
        return response;
      }
    });
    Promise.all(requestList).then(() => {
      //发送请求，通知后端进行合并 //后缀名可通过其他方式获取，这里以.mp4为例
      requestInstance.post(mergeUrl, { fileHash, extname: '.mp4' });
    });
  }
}
```

<font style="color:rgb(38, 38, 38);">在上传时我们调用了</font>`<font style="color:rgb(38, 38, 38);">uploadChunk()</font>`<font style="color:rgb(38, 38, 38);">方法，</font>**<font style="color:rgb(38, 38, 38);">由于我们的请求不仅包含文件，还包含分片索引以及hash值，因此我们的请求体应该是</font>**`**<font style="color:rgb(38, 38, 38);">formData</font>**`**<font style="color:rgb(38, 38, 38);">，还有一点需要就是此时我们传入的</font>**`**<font style="color:rgb(38, 38, 38);">chunk</font>**`**<font style="color:rgb(38, 38, 38);">的类型是</font>**`**<font style="color:rgb(38, 38, 38);">ArrayBuffer</font>**`**<font style="color:rgb(38, 38, 38);">,而formData中文件的类型应该是</font>**`**<font style="color:rgb(38, 38, 38);">Blob</font>**`**<font style="color:rgb(38, 38, 38);">。</font>**<font style="color:rgb(38, 38, 38);"> </font><font style="color:rgb(38, 38, 38);">具体代码如下：</font>

```javascript
async function uploadChunk(chunk, index, fileHash, uploadUrl) {
  let formData = new FormData();
  //注意这里chunk在之前切片之后未ArrayBuffer，而formData接收的数据类型为 blob|string
  formData.append('chunk', new Blob([chunk]));
  formData.append('index', index);
  formData.append('fileHash', fileHash);
  return requestInstance.post(uploadUrl, formData);
}
```

### <font style="color:rgb(38, 38, 38);">前后端代码流程一览</font>
<font style="color:rgb(38, 38, 38);">可能你看完前面还是不是很了解分片上传到底是如何工作的，这里我先给出一个</font>**<font style="color:rgb(38, 38, 38);">示例</font>**<font style="color:rgb(38, 38, 38);">，方便你更好的理解文件在后端是怎么变化的；</font>

<font style="color:rgb(38, 38, 38);">示例：假设此时我们上传一个10Mb的文件，分片大小为5MB，那么前端将传输两个分片；</font>

    1. <font style="color:rgb(38, 38, 38);">服务端接收到一个请求，请求包含分片文件，整个文件的hash，以及分片的索引</font>
    2. <font style="color:rgb(38, 38, 38);">然后服务端将会创建一个</font>**<font style="color:rgb(38, 38, 38);">文件夹</font>**<font style="color:rgb(38, 38, 38);">，文件夹名为hash值；</font>
    3. <font style="color:rgb(38, 38, 38);">然后将分片命名为</font>`<font style="color:rgb(38, 38, 38);">chunk-文件索引</font>`<font style="color:rgb(38, 38, 38);">保存在文件夹中；</font>
+ <font style="color:rgb(38, 38, 38);">上述三个步骤就是我们判断文件上传状态的依据，我们只需要知道文件的hash以及文件的总分块数就可以判断了；</font>

![](https://cdn.nlark.com/yuque/0/2024/png/207857/1728637248107-179bf62b-b82b-4430-9d6f-6654eabc948a.png)

### 优化
<font style="color:rgb(38, 38, 38);">当文件非常大的时候，我们计算其Hash值是十分耗时的，为了解决</font>**<font style="color:rgb(38, 38, 38);">Hash计算耗时问题</font>**<font style="color:rgb(38, 38, 38);">，我们可以采取以下优化方案：</font>

+ <font style="color:rgb(38, 38, 38);">使用</font>`<font style="color:rgb(38, 38, 38);">Web Worker</font>`<font style="color:rgb(38, 38, 38);">,不占用主线程资源，在后台线程中计算；</font>
+ <font style="color:rgb(38, 38, 38);">不再Hash整个文件，而是采用一些其他策略;</font>

<font style="color:rgb(38, 38, 38);"></font>

#### <font style="color:rgb(38, 38, 38);">Web Worker</font>
```javascript
async function uploadFile(file, baseChunkSize, uploadUrl, vertifyUrl, mergeUrl, progress_cb) {
  //创建文件分片Worker
  const sliceFileWorker = new Worker(new URL('./sliceFileWorker.js', import.meta.url), { type: 'module' });
  //将文件以及分块大小通过postMessage发送给sliceFileWorker线程
  sliceFileWorker.postMessage({ targetFile: file, baseChunkSize })、
  //分片处理完之后触发onmessage事件
  sliceFileWorker.onmessage = async (e) => {
    //获取处理结果
    const { chunkList, fileHash } = e.data;
    //后续代码与之前一样
    ...
  }
}
```



```javascript
self.onmessage = async (e) => {
  //获取文件以及分块大小传输
  const { targetFile, baseChunkSize } = e.data;
  //分片并计算Hash
  const { chunkList, fileHash } = await sliceFile(targetFile, baseChunkSize);
  //将计算结果通过postMessage发送给主线程
  self.postMessage({ chunkList, fileHash });
}

async function sliceFile(targetFile, baseChunkSize = 1) {
    //与之前一样
    ...
}
```

#### <font style="color:rgb(38, 38, 38);">Hash策略</font>
<font style="color:rgb(38, 38, 38);">我们不一定非要Hash整个文件，可以采用以下策略：</font>

+ <font style="color:rgb(38, 38, 38);">仅Hash文件的第一个分片 + 中间分片的首尾n字节 + 最后一个分片</font>

![](https://cdn.nlark.com/yuque/0/2024/png/207857/1728636569044-963d0117-d76b-4ee0-a5e7-7e3f73937aeb.png)





### <font style="color:rgb(38, 38, 38);">总结</font>
<font style="color:rgb(38, 38, 38);">文件的分片上传功能的注意点:</font>

+ <font style="color:rgb(38, 38, 38);">利用</font><font style="color:rgb(38, 38, 38);"> </font>`<font style="color:rgb(38, 38, 38);">FileReader.onload</font>`<font style="color:rgb(38, 38, 38);"> </font><font style="color:rgb(38, 38, 38);">读取分片，利用</font><font style="color:rgb(38, 38, 38);"> </font>`<font style="color:rgb(38, 38, 38);">spark-md5</font>`<font style="color:rgb(38, 38, 38);"> </font><font style="color:rgb(38, 38, 38);">第三方库对文件进行hash计算</font>
+ `<font style="color:rgb(38, 38, 38);">formData</font>`<font style="color:rgb(38, 38, 38);"> </font><font style="color:rgb(38, 38, 38);">类型的请求体中，文件等二进制数据应以</font><font style="color:rgb(38, 38, 38);"> </font>`<font style="color:rgb(38, 38, 38);">Blob</font>`<font style="color:rgb(38, 38, 38);"> </font><font style="color:rgb(38, 38, 38);">类型传输</font>
+ `<font style="color:rgb(38, 38, 38);">Promise.all</font>`<font style="color:rgb(38, 38, 38);"> </font><font style="color:rgb(38, 38, 38);">中获取请求进度可以使用回调来更新进度;</font>
+ <font style="color:rgb(38, 38, 38);">后端代码编写时要正确的区分</font>**<font style="color:rgb(38, 38, 38);">文件和文件夹</font>**<font style="color:rgb(38, 38, 38);">的区别；</font>

<font style="color:rgb(38, 38, 38);"></font>

<font style="color:rgb(38, 38, 38);"></font>

### <font style="color:rgb(38, 38, 38);">代码</font>
#### 前端代码
```javascript
import SparkMD5 from 'spark-md5';
import requestInstance from '../request';

/**
 * @param {File} targetFile 目标上传文件
 * @param {number} baseChunkSize 上传分块大小，单位Mb
 * @param {string} uploadUrl 上传文件的后端接口地址
 * @param {string} vertifyUrl 验证文件上传的接口地址
 * @param {*} mergeUrl 请求进行文件合并的接口地址
 * @returns
 */
async function uploadFile(file, baseChunkSize, uploadUrl, vertifyUrl, mergeUrl, progress_cb) {
  const sliceFileWorker = new Worker(new URL('./sliceFileWorker.js', import.meta.url), { type: 'module' });
  sliceFileWorker.postMessage({ targetFile: file, baseChunkSize })
  sliceFileWorker.onmessage = async (e) => {
    const { chunkList, fileHash } = e.data;
    //所有分片 ArrayBuffer[]
    let allChunkList = chunkList;
    //需要上传的分片序列 number[]
    let neededChunkList = [];
    //上传进度
    let progress = 0;
    //发送请求,获取文件上传状态
    if (vertifyUrl) {
      const { data } = await requestInstance.post(vertifyUrl, {
        fileHash,
        totalCount: allChunkList.length,
        extname: '.' + file.name.split('.').pop(),
      });
      const { neededFileList, message } = data;
      if (message) console.info(message);
      //无待上传文件，秒传
      if (!neededFileList.length) return;

      //部分上传成功，更新unUploadChunkList
      neededChunkList = neededFileList;
    }

    //同步上传进度，断点续传情况下
    progress = ((allChunkList.length - neededChunkList.length) / allChunkList.length) * 100;

    //上传
    if (allChunkList.length) {
      const requestList = allChunkList.map(async (chunk, index) => {
        if (neededChunkList.includes(index + 1)) {
          const response = await uploadChunk(chunk, index + 1, fileHash, uploadUrl);

          //更新进度
          progress += Math.ceil(100 / allChunkList.length);
          if (progress >= 100) progress = 100;
          progress_cb(progress);
          return response;
        }
      });
      Promise.all(requestList).then(() => {
        //发送请求，通知后端进行合并
        requestInstance.post(mergeUrl, { fileHash, extname: '.mp4' });
      });
    }
  }
}

async function uploadChunk(chunk, index, fileHash, uploadUrl) {
  let formData = new FormData();
  //注意这里chunk在之前切片之后未ArrayBuffer，而formData接收的数据类型为 blob|string
  formData.append('chunk', new Blob([chunk]));
  formData.append('index', index);
  formData.append('fileHash', fileHash);
  return requestInstance.post(uploadUrl, formData);
}

/**
 * 将目标文件分片 并 计算文件Hash
 * @param {File} targetFile 目标上传文件
 * @param {number} baseChunkSize 上传分块大小，单位Mb
 * @returns {chunkList:ArrayBuffer,fileHash:string}
 */
// eslint-disable-next-line no-unused-vars
async function sliceFile(targetFile, baseChunkSize = 1) {
  return new Promise((resolve, reject) => {
    //初始化分片方法，兼容问题
    let blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice;
    //分片大小 baseChunkSize Mb
    let chunkSize = baseChunkSize * 1024 * 1024;
    //目标分片数
    let targetChunkCount = targetFile && Math.ceil(targetFile.size / chunkSize);
    //当前已执行分块数
    let currentChunkCount = 0;
    //创建sparkMD5对象
    let spark = new SparkMD5.ArrayBuffer();
    //创建文件读取对象
    let fileReader = new FileReader();
    let chunkList = [];
    let fileHash = null;

    //FilerReader onload事件
    fileReader.onload = (e) => {
      //当前读取的分块结果 ArrayBuffer
      const curChunk = e.target.result;
      //将当前分块追加到spark对象中
      spark.append(curChunk);
      currentChunkCount++;
      chunkList.push(curChunk);
      //判断分块是否全部读取成功
      if (currentChunkCount >= targetChunkCount) {
        //全部读取，获取文件hash
        fileHash = spark.end();
        resolve({ chunkList, fileHash });
      } else {
        loadNext();
      }
    };

    //FilerReader onerror事件
    fileReader.onerror = () => {
      reject(null);
    };

    //读取下一个分块
    const loadNext = () => {
      //计算分片的起始位置和终止位置
      const start = chunkSize * currentChunkCount;
      let end = start + chunkSize;
      if (end > targetFile.size) {
        end = targetFile.size;
      }
      //读取文件，触发onLoad
      fileReader.readAsArrayBuffer(blobSlice.call(targetFile, start, end));
    };

    loadNext();
  });
}

export { uploadFile };

```

```javascript
import SparkMD5 from 'spark-md5';

self.onmessage = async (e) => {
  const { targetFile, baseChunkSize } = e.data;
  const { chunkList, fileHash } = await sliceFile(targetFile, baseChunkSize);
  self.postMessage({ chunkList, fileHash });
}

/**
 * 将目标文件分片 并 计算文件Hash
 * @param {File} targetFile 目标上传文件
 * @param {number} baseChunkSize 上传分块大小，单位Mb
 * @returns {chunkList:ArrayBuffer,fileHash:string}
 */
async function sliceFile(targetFile, baseChunkSize = 1) {
  return new Promise((resolve, reject) => {
    //初始化分片方法，兼容问题
    let blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice;
    //分片大小 baseChunkSize Mb
    let chunkSize = baseChunkSize * 1024 * 1024;
    //目标分片数
    let targetChunkCount = targetFile && Math.ceil(targetFile.size / chunkSize);
    //当前已执行分块数
    let currentChunkCount = 0;
    //创建sparkMD5对象
    let spark = new SparkMD5.ArrayBuffer();
    //创建文件读取对象
    let fileReader = new FileReader();
    let chunkList = [];
    let fileHash = null;

    //FilerReader onload事件
    fileReader.onload = (e) => {
      //当前读取的分块结果 ArrayBuffer
      const curChunk = e.target.result;
      //将当前分块追加到spark对象中
      spark.append(curChunk);
      currentChunkCount++;
      chunkList.push(curChunk);
      //判断分块是否全部读取成功
      if (currentChunkCount >= targetChunkCount) {
        //全部读取，获取文件hash
        fileHash = spark.end();
        resolve({ chunkList, fileHash });
      } else {
        loadNext();
      }
    };

    //FilerReader onerror事件
    fileReader.onerror = () => {
      reject(null);
    };

    //读取下一个分块
    const loadNext = () => {
      //计算分片的起始位置和终止位置
      const start = chunkSize * currentChunkCount;
      let end = start + chunkSize;
      if (end > targetFile.size) {
        end = targetFile.size;
      }
      //读取文件，触发onLoad
      fileReader.readAsArrayBuffer(blobSlice.call(targetFile, start, end));
    };

    loadNext();
  });
}
```



#### <font style="color:rgb(38, 38, 38);">后端nodejs代码</font>
```javascript
 
 
  uploadChunk(chunk, chunkInfo) {
    const { fileHash, index } = chunkInfo;

    const dirPath = join(__dirname, '\\uploadedFiles\\chunkFile', fileHash);
    const chunkPath = join(dirPath, `chunk-${index}`);

    //检查文件夹是否存在
    const hasDir = fs.existsSync(dirPath);

    if (hasDir) {
      //检查分块是否存在
      const hasChunk = fs.existsSync(join(dirPath, `chunk-${index}`));

      if (hasChunk) return;
      //添加分块
      fs.writeFile(chunkPath, chunk.buffer, (error) => {
        if (error) {
          console.error(error);
        }
      });
    } else {
      //创建文件夹,并添加当前分片  文件名为fileHash
      new Promise((resolve, reject) => {
        fs.mkdir(
          dirPath,
          {
            recursive: true,
          },
          (error) => {
            if (error) {
              reject(false);
            } else {
              resolve(true);
            }
          },
        );
      }).then((res) => {
        if (res) {
          // 添加当前分片

          fs.writeFile(chunkPath, chunk.buffer, (error) => {
            if (error) {
              console.error(error);
            }
          });
        }
      });
    }
  }

  async vertifyFile(fileHash, totalCount, extname) {
    const dirPath = join(__dirname, '\\uploadedFiles\\chunkFile', fileHash);
    const filePath = dirPath + extname;

    let res = Array(totalCount)
      .fill(0)
      .map((_, index) => index + 1);

    try {
      //读取文件状态
      fs.statSync(filePath);
      //读取成功，即秒传
      return { neededFileList: [], message: '上传成功' };
    } catch (fileError) {
      try {
        fs.statSync(dirPath);
        const files = await fs.readdir(dirPath);
        if (files.length < totalCount) {
          //计算待上传序列
          res = res.filter((fileIndex) => {
            return !files.includes(`chunk-${fileIndex}`);
          });
          return { neededFileList: res };
        } else {
          //未进行合并,去合并
          await this.mergeFile(fileHash, '.mp4');
          return { neededFileList: [], message: '上传成功' };
        }
      } catch (dirError) {
        //读取文件夹失败，返回全序列
        return { neededFileList: res };
      }
    }
  }

  async mergeFile(fileHash, extname) {
    const dirPath = join(__dirname, '\\uploadedFiles\\chunkFile', fileHash);
    const fullPath = join(
      __dirname,
      '\\uploadedFiles\\chunkFile',
      fileHash + extname,
    );

    try {
      // 检查文件是否已存在
      await fs.promises.access(fullPath);
      return '文件已存在';
    } catch (error) {
      // 文件不存在，继续执行
    }

    // 创建写入流
    const writeStream = fs.createWriteStream(fullPath);

    // 读取文件夹，将文件夹中的所有分块进行合并
    try {
      const files = await fs.promises.readdir(dirPath);

      // 对文件进行排序
      files.sort((a, b) => {
        const indexA = parseInt(a.split('-').pop());
        const indexB = parseInt(b.split('-').pop());
        return indexA - indexB;
      });

      // 按顺序写入/合并
      for (let index = 0; index < files.length; index++) {
        const filename = files[index];
        const curFilePath = join(dirPath, filename);
        const readStream = fs.createReadStream(curFilePath);

        // 判断是否是最后一块
        const isLastChunk = index === files.length - 1;

        // 使用 await 确保异步操作完成
        await new Promise((resolve, reject) => {
          readStream.pipe(writeStream, { end: isLastChunk });
          readStream.on('end', resolve);
          readStream.on('error', reject);
        });
      }
    } catch (error) {
      console.error('Error reading directory:', error);
    }

    // 删除保存分块的文件夹
    try {
      await this.removeDir(dirPath);
    } catch (error) {
      console.error('Error removing directory:', error);
    }

    console.log('Files merged successfully');
    const musicFileDto = new CreateMusicDto();
    musicFileDto.name = 'ys upload';
    musicFileDto.singer = 'unknow';
    this.saveFile(musicFileDto, fullPath);
    return '合并完成';
  }

 
```

  


